#!/usr/bin/env python3
"""
Script de validation et am√©lioration de la documentation des hooks prioritaires
V√©rifie la qualit√© de la documentation JSDoc et propose des am√©liorations.
"""

import os
import re
from pathlib import Path
from typing import Dict, List, Tuple

class HookDocumentationValidator:
    def __init__(self, project_root: str):
        self.project_root = Path(project_root)
        self.hooks_dir = self.project_root / "src" / "hooks"
        
        # Hooks prioritaires identifi√©s dans l'audit
        self.priority_hooks = [
            "forms/useFormValidationData.js",
            "forms/useAdminFormValidation.js", 
            "lists/useConcertsList.js",
            "lieux/useLieuxQuery.js",
            "programmateurs/useAdresseValidation.js",
            "contrats/useContratGenerator.js"
        ]
        
        # √âl√©ments requis pour une documentation compl√®te
        self.required_elements = {
            '@description': 'Description d√©taill√©e du hook',
            '@param': 'Documentation des param√®tres',
            '@returns': 'Documentation de la valeur de retour',
            '@example': 'Exemple d\'utilisation',
            '@dependencies': 'D√©pendances du hook',
            '@complexity': 'Niveau de complexit√©',
            '@businessCritical': 'Criticit√© m√©tier'
        }
        
    def analyze_hook_documentation(self, hook_path: str) -> Dict:
        """Analyse la documentation d'un hook sp√©cifique"""
        full_path = self.hooks_dir / hook_path
        
        if not full_path.exists():
            return {
                'exists': False,
                'error': f"Fichier non trouv√©: {hook_path}"
            }
        
        try:
            content = full_path.read_text(encoding='utf-8')
            
            # Extrait le bloc JSDoc principal
            jsdoc_pattern = r'/\*\*(.*?)\*/'
            jsdoc_matches = re.findall(jsdoc_pattern, content, re.DOTALL)
            
            analysis = {
                'exists': True,
                'path': hook_path,
                'file_size': len(content),
                'line_count': len(content.splitlines()),
                'jsdoc_blocks': len(jsdoc_matches),
                'has_main_documentation': False,
                'documentation_score': 0,
                'missing_elements': [],
                'present_elements': [],
                'suggestions': []
            }
            
            # Analyse du bloc principal (le plus long)
            if jsdoc_matches:
                main_jsdoc = max(jsdoc_matches, key=len)
                analysis['has_main_documentation'] = True
                analysis['main_jsdoc_length'] = len(main_jsdoc)
                
                # V√©rifie la pr√©sence des √©l√©ments requis
                for element, description in self.required_elements.items():
                    if element in main_jsdoc:
                        analysis['present_elements'].append(element)
                        analysis['documentation_score'] += 10
                    else:
                        analysis['missing_elements'].append({
                            'element': element,
                            'description': description
                        })
                
                # Bonus pour la qualit√©
                if 'workflow' in main_jsdoc.lower():
                    analysis['documentation_score'] += 5
                if 'errorhandling' in main_jsdoc.lower():
                    analysis['documentation_score'] += 5
                if len(main_jsdoc) > 1000:
                    analysis['documentation_score'] += 10
                    
            else:
                analysis['missing_elements'] = [
                    {'element': element, 'description': description}
                    for element, description in self.required_elements.items()
                ]
            
            # G√©n√®re des suggestions d'am√©lioration
            analysis['suggestions'] = self._generate_suggestions(analysis)
            
            return analysis
            
        except Exception as e:
            return {
                'exists': True,
                'error': f"Erreur lors de l'analyse: {str(e)}"
            }
    
    def _generate_suggestions(self, analysis: Dict) -> List[str]:
        """G√©n√®re des suggestions d'am√©lioration"""
        suggestions = []
        
        if not analysis['has_main_documentation']:
            suggestions.append("üö® CRITIQUE: Ajouter un bloc JSDoc principal au hook")
        
        if analysis['documentation_score'] < 30:
            suggestions.append("‚ö†Ô∏è FAIBLE: Score de documentation tr√®s bas, am√©lioration urgente requise")
        elif analysis['documentation_score'] < 50:
            suggestions.append("üìä MOYEN: Documentation incompl√®te, ajouter les √©l√©ments manquants")
        elif analysis['documentation_score'] < 70:
            suggestions.append("‚úÖ BIEN: Documentation correcte, quelques am√©liorations possibles")
        else:
            suggestions.append("üéâ EXCELLENT: Documentation de qualit√© professionnelle")
        
        # Suggestions sp√©cifiques
        missing_critical = [m for m in analysis['missing_elements'] 
                          if m['element'] in ['@description', '@param', '@returns']]
        if missing_critical:
            suggestions.append("üìù Ajouter la documentation de base: description, param√®tres, retour")
        
        missing_advanced = [m for m in analysis['missing_elements'] 
                          if m['element'] in ['@example', '@dependencies', '@complexity']]
        if missing_advanced:
            suggestions.append("üîß Ajouter la documentation avanc√©e: exemples, d√©pendances, complexit√©")
        
        if analysis.get('line_count', 0) > 200 and '@complexity' not in analysis['present_elements']:
            suggestions.append("‚ö° Hook complexe: Ajouter @complexity et @businessCritical")
        
        return suggestions
    
    def generate_documentation_template(self, hook_path: str, analysis: Dict) -> str:
        """G√©n√®re un template de documentation pour un hook"""
        hook_name = Path(hook_path).stem
        
        template = f"""/**
 * @fileoverview {hook_name} - [DESCRIPTION DU FICHIER]
 * [Description d√©taill√©e de l'objectif du hook]
 * 
 * @author TourCraft Team
 * @since 2024
 */

/**
 * [DESCRIPTION PRINCIPALE DU HOOK]
 * 
 * @description
 * Fonctionnalit√©s principales :
 * - [Fonctionnalit√© 1]
 * - [Fonctionnalit√© 2]
 * - [Fonctionnalit√© 3]
 * 
 * @param {{[TYPE]}} [paramName] - [Description du param√®tre]
 * 
 * @returns {{Object}} [Description de l'objet retourn√©]
 * @returns {{[TYPE]}} returns.[property] - [Description de la propri√©t√©]
 * 
 * @example
 * ```javascript
 * const {{ data, loading, error }} = {hook_name}([params]);
 * 
 * if (loading) return <div>Chargement...</div>;
 * if (error) return <div>Erreur: {{error}}</div>;
 * 
 * // Utiliser les donn√©es
 * ```
 * 
 * @dependencies
 * - [D√©pendance 1]
 * - [D√©pendance 2]
 * 
 * @complexity [LOW|MEDIUM|HIGH]
 * @businessCritical [true|false]
 * @migrationCandidate [Hook g√©n√©rique candidat]
 * 
 * @workflow
 * 1. [√âtape 1]
 * 2. [√âtape 2]
 * 3. [√âtape 3]
 * 
 * @errorHandling
 * - [Type d'erreur 1]: "[Message d'erreur]"
 * - [Type d'erreur 2]: "[Message d'erreur]"
 */"""
        
        return template
    
    def validate_all_priority_hooks(self) -> Dict:
        """Valide tous les hooks prioritaires"""
        print("üîç Validation de la documentation des hooks prioritaires...")
        
        results = {
            'total_hooks': len(self.priority_hooks),
            'analyzed': 0,
            'well_documented': 0,
            'needs_improvement': 0,
            'critical_issues': 0,
            'hooks_analysis': {}
        }
        
        for hook_path in self.priority_hooks:
            print(f"üìã Analyse de {hook_path}...")
            analysis = self.analyze_hook_documentation(hook_path)
            
            if analysis.get('exists', False) and 'error' not in analysis:
                results['analyzed'] += 1
                
                score = analysis.get('documentation_score', 0)
                if score >= 70:
                    results['well_documented'] += 1
                elif score >= 30:
                    results['needs_improvement'] += 1
                else:
                    results['critical_issues'] += 1
                    
                results['hooks_analysis'][hook_path] = analysis
            else:
                results['critical_issues'] += 1
                results['hooks_analysis'][hook_path] = analysis
        
        return results
    
    def generate_improvement_report(self, results: Dict) -> str:
        """G√©n√®re un rapport d'am√©lioration"""
        report = []
        report.append("# üìö RAPPORT DE VALIDATION DOCUMENTATION HOOKS PRIORITAIRES")
        report.append(f"*G√©n√©r√© le: {self._get_current_date()}*\n")
        
        # R√©sum√© ex√©cutif
        report.append("## üìä R√âSUM√â EX√âCUTIF")
        report.append(f"- **Hooks analys√©s**: {results['analyzed']}/{results['total_hooks']}")
        report.append(f"- **Bien document√©s**: {results['well_documented']} (‚â•70 points)")
        report.append(f"- **√Ä am√©liorer**: {results['needs_improvement']} (30-69 points)")
        report.append(f"- **Probl√®mes critiques**: {results['critical_issues']} (<30 points)")
        
        # Calcul du taux de qualit√©
        if results['analyzed'] > 0:
            quality_rate = (results['well_documented'] / results['analyzed']) * 100
            report.append(f"- **Taux de qualit√©**: {quality_rate:.1f}%")
        report.append("")
        
        # Analyse d√©taill√©e par hook
        report.append("## üîç ANALYSE D√âTAILL√âE PAR HOOK")
        
        for hook_path, analysis in results['hooks_analysis'].items():
            if 'error' in analysis:
                report.append(f"### ‚ùå {hook_path}")
                report.append(f"**Erreur**: {analysis['error']}")
                report.append("")
                continue
                
            score = analysis.get('documentation_score', 0)
            status = "üéâ EXCELLENT" if score >= 70 else "üìä MOYEN" if score >= 30 else "üö® CRITIQUE"
            
            report.append(f"### {status} {hook_path}")
            report.append(f"- **Score**: {score}/100")
            report.append(f"- **Lignes**: {analysis.get('line_count', 0)}")
            report.append(f"- **Blocs JSDoc**: {analysis.get('jsdoc_blocks', 0)}")
            
            if analysis.get('present_elements'):
                report.append(f"- **√âl√©ments pr√©sents**: {', '.join(analysis['present_elements'])}")
            
            if analysis.get('missing_elements'):
                report.append("- **√âl√©ments manquants**:")
                for missing in analysis['missing_elements']:
                    report.append(f"  - `{missing['element']}`: {missing['description']}")
            
            if analysis.get('suggestions'):
                report.append("- **Suggestions**:")
                for suggestion in analysis['suggestions']:
                    report.append(f"  - {suggestion}")
            
            report.append("")
        
        # Plan d'action
        report.append("## üìã PLAN D'ACTION PRIORITAIRE")
        
        critical_hooks = [path for path, analysis in results['hooks_analysis'].items() 
                         if analysis.get('documentation_score', 0) < 30]
        
        if critical_hooks:
            report.append("### üö® ACTIONS IMM√âDIATES (Critique)")
            for hook_path in critical_hooks:
                report.append(f"1. **{hook_path}**: Documentation compl√®te requise")
                # G√©n√®re le template
                analysis = results['hooks_analysis'][hook_path]
                template = self.generate_documentation_template(hook_path, analysis)
                report.append(f"   - Template disponible dans le rapport")
        
        improvement_hooks = [path for path, analysis in results['hooks_analysis'].items() 
                           if 30 <= analysis.get('documentation_score', 0) < 70]
        
        if improvement_hooks:
            report.append("### üìä AM√âLIORATIONS (Moyenne priorit√©)")
            for hook_path in improvement_hooks:
                analysis = results['hooks_analysis'][hook_path]
                missing_count = len(analysis.get('missing_elements', []))
                report.append(f"- **{hook_path}**: {missing_count} √©l√©ments manquants")
        
        # Estimation de l'effort
        total_work = len(critical_hooks) * 2 + len(improvement_hooks) * 1  # heures
        report.append(f"\n### ‚è±Ô∏è ESTIMATION DE L'EFFORT")
        report.append(f"- **Hooks critiques**: {len(critical_hooks)} √ó 2h = {len(critical_hooks) * 2}h")
        report.append(f"- **Hooks √† am√©liorer**: {len(improvement_hooks)} √ó 1h = {len(improvement_hooks)}h")
        report.append(f"- **Total estim√©**: {total_work}h ({total_work/8:.1f} jours)")
        
        return "\n".join(report)
    
    def _get_current_date(self):
        """Retourne la date actuelle format√©e"""
        from datetime import datetime
        return datetime.now().strftime("%d/%m/%Y √† %H:%M")

def main():
    """Fonction principale"""
    project_root = os.getcwd()
    validator = HookDocumentationValidator(project_root)
    
    print("üöÄ Validation de la documentation des hooks prioritaires...")
    
    try:
        results = validator.validate_all_priority_hooks()
        report = validator.generate_improvement_report(results)
        
        # Sauvegarde le rapport
        output_file = Path(project_root) / "tools" / "audit" / "validation_documentation_hooks.md"
        output_file.write_text(report, encoding='utf-8')
        
        print(f"‚úÖ Rapport de validation g√©n√©r√©: {output_file}")
        print("\n" + "="*60)
        print(report)
        
    except Exception as e:
        print(f"‚ùå Erreur lors de la validation: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main() 